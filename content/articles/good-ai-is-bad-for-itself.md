---
title: "Good AI Is Bad for Itself—and the Web"
date: 2023-04-09T00:48:11-05:00
---

Over the last 30 years, the internet has accumulated the breadth of human knowledge and experience and placed it at our fingertips. You can find almost anything on the internet—the answer to any question, the text of any book, or a survey of the research of any particular field. AI enthusiasts and tech companies poised to profit off of AI promise that, having been trained on this breadth of knowledge, AI will deliver new ways of retrieving data from the internet to answer just about any question.

However, if AI chatbots truly are successful in wresting a significant number of our queries from the grasp of search engines, they will kick off their own death-spiral. The success of AI will entail its own degradation.

## The degradation of a dataset
Many AI-watchers have already pointed out that the popularity of AI chat products like OpenAI’s ChatGPT or Google’s Bard will trigger a negative feedback loop. Marketers and spammers will saturate the web with AI-generated content. Future models will be trained in this new environment, meaning that inevitably, researchers will scoop up much AI-generated content as they trawl the internet for new data to feed their model. That means new models will be trained on the hallucinations of their forbearers. Without vigorous fine-tuning and careful data sanitation, newer models will end up further removed from reality than earlier models.

This is scary enough, but there’s another way that AI chatbots may create a vicious cycle whose end result is to rot their training dataset (the internet).

## The destruction of the web
Knowledge on the internet exists in a virtuous cycle: a user is interested in the answer to a particular question, so they ask a search engine to answer their question. The search engine returns websites with the answer to this question, and when one of these websites gets traffic from a search, they monetize that traffic in some way. The user gets their question answered and the website gets rewarded for adding a source of new knowledge to the web.

AI disrupts this cycle. When a user asks their question directly to an AI chatbot, no one—other than the website hosting the chatbot—gets traffic from this query. Without traffic, there will no longer be an incentive for a publisher to host a website with the answer to a particular query. Websites hosting knowledge will blink out, starved of their traffic and with them, high-quality sources of training data for AI models will disappear.

Until AI can be trusted not to hallucinate the answers to questions where the truth matters, I expect people will continue to use search engines rather than AI chatbots for their important queries. Without a systematic solution to the problem of hallucinations, it would be unwise to trust an AI over a search engine for the answer to an important question like “how many benadryls should I take for my allergies”. However, even if AI does find a way to guarantee truthful answers to most questions, it will eat itself—and much of the internet.